{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# A Large Dimenional Analysis of LS-SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "by [Zhenyu Liao](http://zhenyu-liao.github.io/), CentraleSupelec, Paris-Saclay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import scipy.special,scipy.linalg\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Get Data (MNIST dataset or Mixture Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_data(testcase,n,n_test,prop,means=None,covs=None):\n",
    "    rng = np.random\n",
    "\n",
    "    # different cases for data\n",
    "    if testcase is 'MNIST':\n",
    "        mnist=fetch_mldata('MNIST original')\n",
    "        X,y = mnist.data,mnist.target\n",
    "        X_train_full, X_test_full = X[:60000], X[60000:]\n",
    "        y_train_full, y_test_full = y[:60000], y[60000:]\n",
    "\n",
    "        selected_target = [7,1]\n",
    "        K=len(selected_target)\n",
    "        X_train = np.array([]).reshape(p,0)\n",
    "        X_test = np.array([]).reshape(p,0)        \n",
    "        \n",
    "        y_train = []\n",
    "        y_test = []\n",
    "        ind=0\n",
    "        for i in selected_target:\n",
    "            locate_target_train = np.where(y_train_full==i)[0][range(np.int(prop[ind]*n))]\n",
    "            locate_target_test  = np.where(y_test_full==i)[0][range(np.int(prop[ind]*n_test))]\n",
    "            X_train = np.concatenate( (X_train,X_train_full[locate_target_train].T),axis=1)\n",
    "            y_train = np.concatenate( (y_train,2*(ind-K/2+.5)*np.ones(np.int(n*prop[ind]))) )\n",
    "            X_test  = np.concatenate( (X_test,X_test_full[locate_target_test].T),axis=1)\n",
    "            y_test = np.concatenate( (y_test,2*(ind-K/2+.5)*np.ones(np.int(n_test*prop[ind]))) )\n",
    "            ind+=1                       \n",
    "        \n",
    "        X_train = X_train - np.mean(X_train,axis=1).reshape(p,1)\n",
    "        X_train = X_train*np.sqrt(784)/np.sqrt(np.sum(X_train**2,(0,1))/n)\n",
    "        \n",
    "        X_test = X_test - np.mean(X_test,axis=1).reshape(p,1)\n",
    "        X_test = X_test*np.sqrt(784)/np.sqrt(np.sum(X_test**2,(0,1))/n_test)\n",
    "        \n",
    "    else:\n",
    "        X_train = np.array([]).reshape(p,0)\n",
    "        X_test = np.array([]).reshape(p,0)       \n",
    "        y_train = []\n",
    "        y_test = []\n",
    "        K = len(prop)\n",
    "        for i in range(K):            \n",
    "            X_train = np.concatenate((X_train,rng.multivariate_normal(means[i],covs[i],size=np.int(n*prop[i])).T),axis=1)\n",
    "            X_test  = np.concatenate((X_test, rng.multivariate_normal(means[i],covs[i],size=np.int(n_test*prop[i])).T),axis=1)\n",
    "            y_train = np.concatenate( (y_train,2*(i-K/2+.5)*np.ones(np.int(n*prop[i]))) )\n",
    "            y_test = np.concatenate( (y_test,2*(i-K/2+.5)*np.ones(np.int(n_test*prop[i]))) )            \n",
    "            \n",
    "    #X_train = X_train/np.sqrt(p)\n",
    "    #X_test  = X_test/np.sqrt(p)\n",
    "            \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generate Kernel function $f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_kernel(kernel,z,derivs=None,tau=None,sigma2=None):\n",
    "    if kernel in ['poly','poly_zero']:\n",
    "        if derivs is None:\n",
    "            print('Error: Try to use poly kernel without derivs given!\\n')\n",
    "        else:\n",
    "            coeffs = np.zeros(3)\n",
    "            for i in range(3):\n",
    "                coeffs[i] = derivs[2-i]/np.math.factorial(2-i)\n",
    "            f = np.polyval(coeffs,(z-tau))\n",
    "    elif kernel is 'gauss':\n",
    "        if sigma2 is None:\n",
    "            print('Error: Try to use Gaussian kernel without sigma given!\\n')\n",
    "        else:\n",
    "            f = np.exp(-z/(2*sigma2))\n",
    "        \n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Get statistics of MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_stat(X,prop):\n",
    "    p = X_train.shape[0]\n",
    "    n = X_train.shape[1]\n",
    "    k = len(prop)\n",
    "    \n",
    "    index = []\n",
    "    means = []\n",
    "    covs = []\n",
    "    tmp = 0\n",
    "    for i in range(k):\n",
    "        index.append(np.arange(tmp,tmp+int(n*prop[i]),1))\n",
    "        means.append(np.mean(X_train[:,index[i]],axis=1).reshape(p,1))\n",
    "        covs.append((X_train[:,index[i]]@X_train[:,index[i]].T/(n*prop[i]) - means[i]@(means[i].T)).reshape(p,p))\n",
    "        tmp = tmp+int(n*prop[i])-1\n",
    "    \n",
    "    return means,covs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "testcase = 'MNIST'# testcase for simulation, among 'iid','means','var','orth','mixed','MNIST'\n",
    "kernel = 'gauss'  # kernel used for LS-SVM, among 'gauss', 'poly', 'poly_zero'\n",
    "\n",
    "n = 1024 # number of training samples \n",
    "n_test = 1024 # number of test simples\n",
    "p = 128 # dimension of data\n",
    "prop = [.25,.75] # two-class problem\n",
    "k = len(prop)\n",
    "\n",
    "gamma = 1\n",
    "\n",
    "\n",
    "loops = 10        # Number of generations of W to be averaged over\n",
    "\n",
    "g=np.zeros((loops,n_test))\n",
    "\n",
    "\n",
    "rng = np.random\n",
    "idx = 0\n",
    "for loop in range(loops):    \n",
    "    \n",
    "    ## Generate X_train,X_test,y_train,y_test\n",
    "    if testcase is 'MNIST':\n",
    "        p=784\n",
    "        X_train,X_test,y_train,y_test = get_data(testcase,n,n_test,prop)\n",
    "    else:    \n",
    "        means=[]\n",
    "        covs=[]\n",
    "        if testcase is 'iid':\n",
    "            for i in range(k):\n",
    "                means.append(np.zeros(p))\n",
    "                covs.append(np.eye(p))     \n",
    "        elif testcase is 'means':\n",
    "            for i in range(k):\n",
    "                means.append( np.concatenate( (np.zeros(i),4*np.ones(1),np.zeros(p-i-1)) ) )\n",
    "                covs.append(np.eye(p))\n",
    "        elif testcase is 'var':\n",
    "            for i in range(k):\n",
    "                means.append(np.zeros(p))\n",
    "                covs.append(np.eye(p)*(1+8*i/np.sqrt(p)))\n",
    "        elif testcase is 'orth':\n",
    "            for i in range(k):\n",
    "                means.append(np.zeros(p))\n",
    "                covs.append( np.diag(np.concatenate( (np.ones(np.int(np.sum(prop[0:i]*p))),4*np.ones(np.int(prop[i]*p)),np.ones(np.int(np.sum(prop[i+1:]*p))) ) ) ))\n",
    "        elif testcase is 'mixed':\n",
    "            for i in range(k):\n",
    "                means.append( np.concatenate( (np.zeros(i),2*np.ones(1),np.zeros(p-i-1)) ) )\n",
    "                covs.append((1+4*i/np.sqrt(p))*scipy.linalg.toeplitz( [(.4*i)**x for x in range(p)] ))            \n",
    "\n",
    "        X_train,X_test,y_train,y_test = get_data(testcase,n,n_test,prop,means,covs)\n",
    "\n",
    "    # computation of tau\n",
    "    XX_train = X_train.T@X_train/p\n",
    "    XX_test = X_test.T@X_test/p\n",
    "    tau = 2*np.trace(XX_train)/n\n",
    "\n",
    "    \n",
    "    # Build kernel matrix K\n",
    "    if kernel is 'gauss':\n",
    "        sigma2 = 1\n",
    "        derivs = None\n",
    "    elif kernel is 'poly':\n",
    "        sigma2 = None\n",
    "        derivs = [3, -.5, 2]\n",
    "    elif kernel is 'poly_zero':\n",
    "        sigma2 = None\n",
    "        derivs = [3, 0, 2]\n",
    "    \n",
    "    K = get_kernel(kernel, XX_train.diagonal(offset=0).reshape(n,1)@np.ones(n).reshape(1,n)+np.ones(n).reshape(n,1)@XX_train.diagonal(offset=0).T.reshape(1,n)-2*XX_train, derivs, tau, sigma2)\n",
    "    # print(K.shape)\n",
    "\n",
    "    S = K + n/gamma*np.eye(n)\n",
    "    invS_y = scipy.linalg.solve(S,y_train)\n",
    "    invS_1 = scipy.linalg.solve(S,np.ones(n))\n",
    "\n",
    "    # b = invS_y.sum()/invS_1.sum()\n",
    "    # alpha = invS_y - invS_1*b\n",
    "    # g[idx] = alpha.T@get_kernel(kernel, XX_train.diagonal(offset=0).reshape(n,1)@(np.ones(n_test).reshape(1,n_test))+np.ones(n).reshape(n,1)@XX_test.diagonal(offset=0).reshape(1,n_test)-2*X_train.T@X_test/p, derivs, tau, sigma2)+b\n",
    "    \n",
    "    # if we remove b\n",
    "    alpha = invS_y\n",
    "    g[idx] = alpha.T@get_kernel(kernel, XX_train.diagonal(offset=0).reshape(n,1)@(np.ones(n_test).reshape(1,n_test))+np.ones(n).reshape(n,1)@XX_test.diagonal(offset=0).reshape(1,n_test)-2*X_train.T@X_test/p, derivs, tau, sigma2)\n",
    "    \n",
    "    idx += 1\n",
    "    \n",
    "# Computation for theoritical means and var\n",
    "if kernel is 'gauss':\n",
    "    f_tau = get_kernel(kernel,tau,derivs,tau,sigma2)\n",
    "    derivs = [f_tau, -f_tau/(2*sigma2), f_tau/(4*sigma2**2)]\n",
    "    \n",
    "if testcase is 'MNIST':\n",
    "    means,covs = get_stat(X_train,prop)\n",
    "\n",
    "\n",
    "t1 = np.trace(covs[0]-prop[0]*covs[0]-prop[1]*covs[1])/np.sqrt(p)\n",
    "t2 = np.trace(covs[1]-prop[0]*covs[0]-prop[1]*covs[1])/np.sqrt(p)\n",
    "    \n",
    "D = -2*derivs[1]*(np.linalg.norm(means[1]-means[0]))**2/p + derivs[2]*(t1-t2)**2/p + 2*derivs[2]*(np.trace((covs[0]-covs[1])**2))/(p**2)\n",
    "\n",
    "mean_th = (prop[1]-prop[0])*np.array([1.0,1.0])+2*prop[0]*prop[1]*gamma*D*np.array([-prop[1],prop[0]])\n",
    "V11 = (t2-t1)**2*derivs[2]**2*np.trace(covs[0]**2)/(p**3)\n",
    "V12 = (t2-t1)**2*derivs[2]**2*np.trace(covs[1]**2)/(p**3)\n",
    "V21 = 2*derivs[1]**2*(means[1]-means[0]).T@covs[0]@(means[1]-means[0])/(p**2)\n",
    "V22 = 2*derivs[1]**2*(means[1]-means[0]).T@covs[1]@(means[1]-means[0])/(p**2)\n",
    "V31 = 2*derivs[1]**2*(np.trace(covs[0]**2)/prop[0]+np.trace(covs[0]*covs[1])/prop[1])/(n*p**2)\n",
    "V32 = 2*derivs[1]**2*(np.trace(covs[0]*covs[1])/prop[0]+np.trace(covs[1]**2)/prop[1])/(n*p**2)\n",
    "var_th = 8*gamma**2*(prop[0]*prop[1])**2*np.array([V11+V21+V31, V12+V22+V32])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c816470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.134470710685\n",
      "shoud be the centre of two histograms\n"
     ]
    }
   ],
   "source": [
    "if g.shape == (n_test,loops):\n",
    "    g = g\n",
    "    print('yes')\n",
    "else:\n",
    "    g = g.T\n",
    "\n",
    "g1 = g[range(int(n_test*prop[0])),:]\n",
    "g2 = g[int(n_test*prop[0]):,:]\n",
    "\n",
    "xs1 = np.linspace(min(g1.flatten()),max(g1.flatten()),30)\n",
    "xs2 = np.linspace(min(g2.flatten()),max(g2.flatten()),30)\n",
    "g_th1 = scipy.stats.norm.pdf((xs1-mean_th[0])/np.sqrt(var_th[0])).reshape(30,1)\n",
    "g_th2 = scipy.stats.norm.pdf((xs2-mean_th[1])/np.sqrt(var_th[1])).reshape(30,1)\n",
    "\n",
    "n1, bins1, patches1 ,= plt.hist(g1.flatten(), 30, normed=True, facecolor='blue', alpha=0.75)\n",
    "n2, bins2, patches2 ,= plt.hist(g2.flatten(), 30, normed=True, facecolor='red', alpha=0.75)\n",
    "\n",
    "# pl1 ,=plt.plot(xs1,g_th1*n_test,'green')\n",
    "# pl2 ,=plt.plot(xs2,g_th2*n_test,'purple')\n",
    "plt.show()\n",
    "print(gamma*derivs[0]/(1+gamma*derivs[0])*(prop[1]-prop[0]))\n",
    "print('shoud be the centre of two histograms')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
